# -*- coding: utf-8 -*-
"""ProjecteSiamesa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VZEYXRChHOaiLYjQs5xGQgGlsZkAIxzT

**Dataset Handwritten Signatures**

https://www.kaggle.com/divyanshrai/handwritten-signatures

30 people with 1 true signature and 4 false signature each one
"""

from keras.layers import Dense, Conv2D, MaxPool2D
from sklearn.model_selection import train_test_split
from keras.models import Model
from keras.layers import Input, Dense, Lambda
import pandas as pd
import numpy as np
import os
import keras
import matplotlib.pyplot as plt
from keras.optimizers import Adam
import tensorflow as tf
from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
import random

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse

from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

!mkdir -p drive
!google-drive-ocamlfuse drive

print('Files in Drive:')
PATH1 = "drive/JEDI DEEP/DATASET_SIGNATURE/FORGE/"
PATH2 = "drive/JEDI DEEP/DATASET_SIGNATURE/REAL/"

from PIL import ImageFilter
from PIL import Image

def imageprepare(argv):
    im = Image.open(argv).convert('L')
    width = float(im.size[0])
    height = float(im.size[1])
    newImage = Image.new('L', (28, 28), (255))  # creates white canvas of 28x28 pixels

    if width > height:  # check which dimension is bigger
        # Width is bigger. Width becomes 20 pixels.
        nheight = int(round((20.0 / width * height), 0))  # resize height according to ratio width
        if (nheight == 0):  # rare case but minimum is 1 pixel
            nheight = 1
            # resize and sharpen
        img = im.resize((20, nheight), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)
        wtop = int(round(((28 - nheight) / 2), 0))  # calculate horizontal position
        newImage.paste(img, (4, wtop))  # paste resized image on white canvas
    else:
        # Height is bigger. Heigth becomes 20 pixels.
        nwidth = int(round((20.0 / height * width), 0))  # resize width according to ratio height
        if (nwidth == 0):  # rare case but minimum is 1 pixel
            nwidth = 1
            # resize and sharpen
        img = im.resize((nwidth, 20), Image.ANTIALIAS).filter(ImageFilter.SHARPEN)
        wleft = int(round(((28 - nwidth) / 2), 0))  # caculate vertical pozition
        newImage.paste(img, (wleft, 4))  # paste resized image on white canvas

    # newImage.save("sample.png

    tv = np.array(newImage.getdata())  # get pixel values

    # normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.
    tva = [(255 - x) * 1.0 / 255.0 for x in tv]
    return tva

import os
from PIL import Image

forge = []
real = []
for file in os.listdir(PATH1):
    filename = PATH1 + os.fsdecode(file)
    np_im = imageprepare(filename)
    forge.append(np_im)
    
for file in os.listdir(PATH2):
    filename = PATH2 + os.fsdecode(file)
    np_im = imageprepare(filename)
    real.append(np_im)

print(len(forge))
forge = np.array(forge)
print(forge.shape)
real = np.array(real)
print(real.shape)
print(len(real))

forge = np.reshape(forge,(62,5,784))
real = np.reshape(real,(43,5,784))

import itertools

def generate_balanced_dataset(train_true, train_false):
  
    dataset = []
    
    print("La shape de train_true es:", np.array(train_true).shape)
    print("La shape de train_false es:", np.array(train_true).shape)
    
        
    for i in train_true:
      
      l = list(itertools.permutations([0,1,2,3,4], r=2))
      
      for j in l:
        dataset.append((i[j[0]],i[j[1]],1))
        
    count = len(dataset)
    
    false = []
    
    for i in train_false:
      l = list(itertools.permutations([0,1,2,3,4], r=2))
      
      for j in l:
        false.append((i[j[0]],i[j[1]]))
        
    while count:
        a = random.choice(false)
        
        if not (a[0] == a[1]).all():
            dataset.append((a[0],a[1], 0))
            count -= 1
            
            
    random.shuffle(dataset)
    x0 = []
    x1 = []
    y = []
    for (d, e, f) in dataset:
        x0.append((np.asanyarray(d)).reshape(28,28,1))
        x1.append((np.asanyarray(e)).reshape(28,28,1))
        y.append(f)
    return np.asanyarray(x0), np.asanyarray(x1), np.asanyarray(y)

def build_siamese_model(input_shape):
    in_img0 = Input(shape=input_shape, name="left_image")
    in_img1 = Input(shape=input_shape, name="right_image")

    model = Sequential()
    model.add( Conv2D(32, (3, 3), activation="relu", input_shape=input_shape) )
    model.add( MaxPooling2D() )
    model.add( Conv2D(64, (3, 3), activation="relu") )
    model.add( MaxPooling2D() )
    model.add( Conv2D(128, (2, 2), activation="relu") )
    model.add( MaxPooling2D() )
    model.add( Conv2D(256, (2, 2), activation="relu") )
    model.add( Flatten() )
    model.add( Dense(1024, activation="sigmoid") )
    model.add( Dropout(0.2) )

    left_part = model(in_img0)
    right_part = model(in_img1)

    operation = Lambda(lambda x:K.abs(x[0] - x[1]))
    distance = operation([left_part, right_part])

    prediction = Dense(1, activation="sigmoid")(distance)
    return Model(inputs=[in_img0, in_img1], outputs=prediction)

model = build_siamese_model((28, 28, 1))
model.summary()

model.compile(loss="binary_crossentropy", optimizer=Adam(lr = 0.0001), metrics=["accuracy"])

a = len(forge)
b = len(real)

x_test_false = []
x_train_false = []
x_test_true = []
x_train_true = []

for i in range(a):
  if i < (0.66*a):
    x_train_false.append(forge[i])
  else:
    x_test_false.append(forge[i])

for i in range(b):
  if i < (0.66*b):
    x_train_true.append(real[i])
  else:
    x_test_true.append(real[i])

    
print(len(x_train_true))
print(len(x_train_false))
print(len(x_test_true))
print(len(x_test_false))

left_train, right_train, y = generate_balanced_dataset(x_train_true, x_train_false)
left_test, right_test, y_test = generate_balanced_dataset(x_test_true, x_test_false)

print(left_train.shape)

history = model.fit(x=[left_train, right_train], y=y, batch_size=32, epochs=2, verbose=1,validation_data=([left_test, right_test], y_test))

print(history.history.keys())

# Plot del Acc
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# Plot del Loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

def prediction(left, right):
    pred = model.predict([np.reshape(left, (1, 28, 28, 1)), np.reshape(right, (1, 28, 28, 1))])
    if pred >= 0.5:
        print("Iguales (% {})".format(pred))
    else:
        print("Diferentes (% {})".format(pred))
    plt.title('Left Image')
    plt.imshow(np.reshape(left, (28, 28)))
    plt.show()
    plt.title('Right Image')
    plt.imshow(np.reshape(right, (28, 28)))
    plt.show()

prediction(x_test_true[0][0], x_test_true[1][1])